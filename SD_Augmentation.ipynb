{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SD Augmentation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Katonokatono/Suicide/blob/Preprocessing/SD_Augmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GU28_BTGqVIf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "outputId": "05aa096c-1970-439b-8f85-82c702a62fc1"
      },
      "source": [
        "# Loading the dataset\n",
        "import pandas as pd\n",
        "df = pd.read_csv('/content/final_data_suicide-UNP-1.csv')\n",
        "df.head()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>tweet</th>\n",
              "      <th>friends_count</th>\n",
              "      <th>followers_count</th>\n",
              "      <th>statuses_count</th>\n",
              "      <th>created_at</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>label</th>\n",
              "      <th>town</th>\n",
              "      <th>clean_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>BunMo Multi Item Stretchy Strings Fidget Toy 6...</td>\n",
              "      <td>182</td>\n",
              "      <td>83</td>\n",
              "      <td>6950</td>\n",
              "      <td>09/14/2021 7:47</td>\n",
              "      <td>0</td>\n",
              "      <td>anxiety</td>\n",
              "      <td>burundi</td>\n",
              "      <td>bunmo multi item stretchy string fidget toy pk...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>@unkonfined The basic motivation behind our be...</td>\n",
              "      <td>983</td>\n",
              "      <td>915</td>\n",
              "      <td>12944</td>\n",
              "      <td>09/14/2021 7:31</td>\n",
              "      <td>0</td>\n",
              "      <td>anxiety</td>\n",
              "      <td>kenya</td>\n",
              "      <td>unkonfined basic motivation behind behavior bi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>@Munenekimathi5 @zablonorina1 Is your BP norma...</td>\n",
              "      <td>281</td>\n",
              "      <td>63</td>\n",
              "      <td>290</td>\n",
              "      <td>09/14/2021 7:30</td>\n",
              "      <td>0</td>\n",
              "      <td>anxiety</td>\n",
              "      <td>nairobi</td>\n",
              "      <td>munenekimathi zablonorina bp normal yes check ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>How do you deal with being anxious?\\n\\nShare y...</td>\n",
              "      <td>220</td>\n",
              "      <td>2052</td>\n",
              "      <td>37982</td>\n",
              "      <td>09/14/2021 7:02</td>\n",
              "      <td>0</td>\n",
              "      <td>anxiety</td>\n",
              "      <td>nairobi kenya</td>\n",
              "      <td>deal anxious share experience anxiety yvonne m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Did you know ‚Äòdry spell‚Äô causes anxiety, depre...</td>\n",
              "      <td>857</td>\n",
              "      <td>272</td>\n",
              "      <td>650</td>\n",
              "      <td>09/14/2021 7:00</td>\n",
              "      <td>2</td>\n",
              "      <td>general tweet</td>\n",
              "      <td>nairobi</td>\n",
              "      <td>know dry spell cause anxiety depression even s...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                         clean_text\n",
              "0           1  ...  bunmo multi item stretchy string fidget toy pk...\n",
              "1           2  ...  unkonfined basic motivation behind behavior bi...\n",
              "2           3  ...  munenekimathi zablonorina bp normal yes check ...\n",
              "3           4  ...  deal anxious share experience anxiety yvonne m...\n",
              "4           5  ...  know dry spell cause anxiety depression even s...\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGUxa2R2RmE1"
      },
      "source": [
        "%%capture\n",
        "!pip install nlpaug\n",
        "!pip install transformers"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPgd8lbFRvBA"
      },
      "source": [
        "# Loading the required augmentation Libraries\n",
        "import nlpaug.augmenter.char as nac\n",
        "import nlpaug.augmenter.word as naw\n",
        "import nlpaug.augmenter.sentence as nas\n",
        "import nlpaug.flow as naf\n",
        "from tqdm import tqdm\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "from nlpaug.util import Action"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CmT4pqWoR5WG",
        "outputId": "95364005-4ae7-40e3-ed14-713ccae3d820"
      },
      "source": [
        "#Split the train and test data\n",
        "from sklearn.model_selection import train_test_split\n",
        "train,valid=train_test_split(df,test_size=0.20 , stratify = df['label'])\n",
        "train.shape, valid.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((3337, 10), (835, 10))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXdeeDuCQhKe"
      },
      "source": [
        "valid.to_csv('VAlid dataset.csv')"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YyQTdao2SSmu",
        "outputId": "990e303c-3962-4256-abe9-ef01196eb9f3"
      },
      "source": [
        "# Check the size of our columns so as to know how to augment each column\n",
        "train['label'].value_counts()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "general tweet      2088\n",
              "awareness           382\n",
              "anxiety             286\n",
              "depression          284\n",
              "substance abuse     107\n",
              "thoughts            103\n",
              "stress               87\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HB4fc8iShAM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "a70a379c-662e-4890-eac5-1a4acae444dc"
      },
      "source": [
        "# Test text to check augmentation quality.\n",
        "text = train.iloc[0]['tweet']\n",
        "text"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Check out our youtube channel for our latest video on World Suicide Prevention Day!  '"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6HY40qrWSsJ7",
        "outputId": "0a2dac30-50b3-49fa-b82f-06dbaead1644"
      },
      "source": [
        "# ContextualWordEmbsAug : Augmenter that apply operation (word level) to textual input based on contextual word embeddings.\n",
        "\n",
        "aug = naw.ContextualWordEmbsAug(\n",
        "    model_path='bert-base-uncased', action=\"insert\")\n",
        "augmented_text = aug.augment(text)\n",
        "\n",
        "\n",
        "print('Original text \\n',text,'\\n Augmented text\\n', augmented_text)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text \n",
            " Check out our youtube channel for our latest video on World Suicide Prevention Day!   \n",
            " Augmented text\n",
            " can check out her our youtube channel there for our latest video session on world suicide prevention day!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuZR8eagS-GV"
      },
      "source": [
        "# Creating a copy of  the dataset\n",
        "df1 = df.copy(deep=True)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "aiVap8hCtzhj",
        "outputId": "6962d07b-f991-496c-c3bc-a8da8df2d417"
      },
      "source": [
        "import numpy as np\n",
        "#For anxiety, class = 0,\n",
        "\n",
        "# Creating augmented text data to increase our training dataset by 214 entries\n",
        "\n",
        "def augment_text(df1,samples=214,pr=0.2):   \n",
        "    aug.aug_p=pr\n",
        "    new_text=[]\n",
        "    \n",
        "    #selecting the  class samples\n",
        "    df_n=df1[df1['label']=='anxiety'].reset_index(drop=True)\n",
        "\n",
        "    ## data augmentation loop\n",
        "    for i in tqdm(np.random.randint(0,len(df_n),samples)):\n",
        "        \n",
        "            text = df_n.iloc[i]['tweet']\n",
        "            augmented_text = aug.augment(text)\n",
        "            new_text.append(augmented_text)\n",
        "    \n",
        "    \n",
        "    ## dataframe\n",
        "    new=pd.DataFrame({'tweet':new_text,'label':'anxiety'})\n",
        "    df1=shuffle(df1.append(new).reset_index(drop=True))\n",
        "    return df1\n",
        "   \n",
        "train = augment_text(train)\n",
        "print(train.shape, '\\n\\n')\n",
        "train.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 214/214 [02:38<00:00,  1.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3551, 10) \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>tweet</th>\n",
              "      <th>friends_count</th>\n",
              "      <th>followers_count</th>\n",
              "      <th>statuses_count</th>\n",
              "      <th>created_at</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>label</th>\n",
              "      <th>town</th>\n",
              "      <th>clean_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1691</th>\n",
              "      <td>328.0</td>\n",
              "      <td>Sex doesn‚Äôt have to be a daily indulgence, lik...</td>\n",
              "      <td>1816</td>\n",
              "      <td>56476.0</td>\n",
              "      <td>61451.0</td>\n",
              "      <td>14-09-21 4:00</td>\n",
              "      <td>0</td>\n",
              "      <td>general tweet</td>\n",
              "      <td>nairobi</td>\n",
              "      <td>sex doesnt daily indulgence like prescription ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>865</th>\n",
              "      <td>97.0</td>\n",
              "      <td>I'm too anxious for this</td>\n",
              "      <td>512</td>\n",
              "      <td>1833.0</td>\n",
              "      <td>28515.0</td>\n",
              "      <td>09/12/2021 6:40</td>\n",
              "      <td>0</td>\n",
              "      <td>general tweet</td>\n",
              "      <td>mombasa</td>\n",
              "      <td>anxious</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>435</th>\n",
              "      <td>7.0</td>\n",
              "      <td>I get so anxious whenever I'm going anywhere o...</td>\n",
              "      <td>1427</td>\n",
              "      <td>12980.0</td>\n",
              "      <td>139126.0</td>\n",
              "      <td>09/17/2021 14:41</td>\n",
              "      <td>0</td>\n",
              "      <td>anxiety</td>\n",
              "      <td>nairobi</td>\n",
              "      <td>get anxious whenever go anywhere house lol</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>753</th>\n",
              "      <td>257.0</td>\n",
              "      <td>Steve Biko: I have no good things to say about...</td>\n",
              "      <td>158</td>\n",
              "      <td>3486941.0</td>\n",
              "      <td>602880.0</td>\n",
              "      <td>09-10-21 4:04</td>\n",
              "      <td>11</td>\n",
              "      <td>general tweet</td>\n",
              "      <td>nairobi</td>\n",
              "      <td>steve biko good thing say young people leaders...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>307</th>\n",
              "      <td>274.0</td>\n",
              "      <td>Dear,Good morning,and hope this weekend will w...</td>\n",
              "      <td>2030</td>\n",
              "      <td>4291.0</td>\n",
              "      <td>14939.0</td>\n",
              "      <td>2021-09-12 08:34:02</td>\n",
              "      <td>0</td>\n",
              "      <td>general tweet</td>\n",
              "      <td>nairobi</td>\n",
              "      <td>dear good morning hope weekend work gateway he...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Unnamed: 0  ...                                         clean_text\n",
              "1691       328.0  ...  sex doesnt daily indulgence like prescription ...\n",
              "865         97.0  ...                                            anxious\n",
              "435          7.0  ...         get anxious whenever go anywhere house lol\n",
              "753        257.0  ...  steve biko good thing say young people leaders...\n",
              "307        274.0  ...  dear good morning hope weekend work gateway he...\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 506
        },
        "id": "cg2DIuTlTKrI",
        "outputId": "f9356339-5a81-4425-c3d7-684c58ad242f"
      },
      "source": [
        "import numpy as np\n",
        "#For awareness, \n",
        "\n",
        "# Creating augmented text data to increase our training dataset by 118 entries\n",
        "\n",
        "def augment_text(df1,samples=118,pr=0.2):   \n",
        "    aug.aug_p=pr\n",
        "    new_text=[]\n",
        "    \n",
        "    #selecting the  class samples\n",
        "    df_n=df1[df1['label']=='awareness'].reset_index(drop=True)\n",
        "\n",
        "    ## data augmentation loop\n",
        "    for i in tqdm(np.random.randint(0,len(df_n),samples)):\n",
        "        \n",
        "            text = df_n.iloc[i]['clean_text']\n",
        "            augmented_text = aug.augment(text)\n",
        "            new_text.append(augmented_text)\n",
        "    \n",
        "    \n",
        "    ## dataframe\n",
        "    new=pd.DataFrame({'clean_text':new_text,'label':'awareness'})\n",
        "    df1=shuffle(df1.append(new).reset_index(drop=True))\n",
        "    return df1\n",
        "   \n",
        "train = augment_text(train)\n",
        "print(train.shape, '\\n\\n')\n",
        "train.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 118/118 [00:38<00:00,  3.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3669, 10) \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>tweet</th>\n",
              "      <th>friends_count</th>\n",
              "      <th>followers_count</th>\n",
              "      <th>statuses_count</th>\n",
              "      <th>created_at</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>label</th>\n",
              "      <th>town</th>\n",
              "      <th>clean_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3168</th>\n",
              "      <td>52.0</td>\n",
              "      <td>@PlutusTheFarmer For me it‚Äôs the anxiety and h...</td>\n",
              "      <td>360</td>\n",
              "      <td>1264.0</td>\n",
              "      <td>16875.0</td>\n",
              "      <td>09/13/2021 15:20</td>\n",
              "      <td>0</td>\n",
              "      <td>general tweet</td>\n",
              "      <td>kenya</td>\n",
              "      <td>plutusthefarmer anxiety deal rude ppl always g...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1596</th>\n",
              "      <td>31.0</td>\n",
              "      <td>@RailaOdinga Thank you Baba for coming to our ...</td>\n",
              "      <td>78</td>\n",
              "      <td>90.0</td>\n",
              "      <td>306.0</td>\n",
              "      <td>2021-09-16 16:15:33</td>\n",
              "      <td>0</td>\n",
              "      <td>general tweet</td>\n",
              "      <td>nairobi</td>\n",
              "      <td>railaodinga thank baba come aid almost die let...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1738</th>\n",
              "      <td>217.0</td>\n",
              "      <td>@gufydox Call a psychologist you know and trus...</td>\n",
              "      <td>1345</td>\n",
              "      <td>757.0</td>\n",
              "      <td>1401.0</td>\n",
              "      <td>09/11/2021 1:55</td>\n",
              "      <td>0</td>\n",
              "      <td>anxiety</td>\n",
              "      <td>nairobi</td>\n",
              "      <td>gufydox call psychologist know trust especiall...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2972</th>\n",
              "      <td>328.0</td>\n",
              "      <td>We need to come together and end stima related...</td>\n",
              "      <td>213</td>\n",
              "      <td>159.0</td>\n",
              "      <td>221.0</td>\n",
              "      <td>9/10/2021 11:05</td>\n",
              "      <td>0</td>\n",
              "      <td>awareness</td>\n",
              "      <td>nairobi</td>\n",
              "      <td>need come together end stima relate suicide</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>373</th>\n",
              "      <td>32.0</td>\n",
              "      <td>@self_essteem Doing drugs</td>\n",
              "      <td>882</td>\n",
              "      <td>420.0</td>\n",
              "      <td>2727.0</td>\n",
              "      <td>09/17/2021 15:01</td>\n",
              "      <td>0</td>\n",
              "      <td>general tweet</td>\n",
              "      <td>nairobi</td>\n",
              "      <td>self essteem drug</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Unnamed: 0  ...                                         clean_text\n",
              "3168        52.0  ...  plutusthefarmer anxiety deal rude ppl always g...\n",
              "1596        31.0  ...  railaodinga thank baba come aid almost die let...\n",
              "1738       217.0  ...  gufydox call psychologist know trust especiall...\n",
              "2972       328.0  ...        need come together end stima relate suicide\n",
              "373         32.0  ...                                  self essteem drug\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXHu2QRWHpvx",
        "outputId": "159f22d1-6418-42ff-caa8-cb3601c68305"
      },
      "source": [
        "print(train.shape)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3669, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "id": "I1GHJ23vTrHz",
        "outputId": "b7b9ccf1-7af1-4352-8471-639143f7103b"
      },
      "source": [
        "#For depression\n",
        "\n",
        "# Creating augmented text data to increase our training dataset by 216 entries\n",
        "\n",
        "def augment_text(df1,samples=216,pr=0.2):  \n",
        "    aug.aug_p=pr\n",
        "    new_text=[]\n",
        "    \n",
        "    #selecting the  class samples\n",
        "    df_n=df1[df1['label']=='depression'].reset_index(drop=True)\n",
        "\n",
        "    ## data augmentation loop\n",
        "    for i in tqdm(np.random.randint(0,len(df_n),samples)):\n",
        "        \n",
        "            text = df_n.iloc[i]['tweet']\n",
        "            augmented_text = aug.augment(text)\n",
        "            new_text.append(augmented_text)\n",
        "    \n",
        "    \n",
        "    ## dataframe\n",
        "    new=pd.DataFrame({'tweet':new_text,'label':'depression'})\n",
        "    df1=shuffle(df1.append(new).reset_index(drop=True))\n",
        "    return df1\n",
        "   \n",
        "train = augment_text(train)\n",
        "print(train.shape, '\\n\\n')\n",
        "train.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 216/216 [03:06<00:00,  1.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3885, 10) \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>tweet</th>\n",
              "      <th>friends_count</th>\n",
              "      <th>followers_count</th>\n",
              "      <th>statuses_count</th>\n",
              "      <th>created_at</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>label</th>\n",
              "      <th>town</th>\n",
              "      <th>clean_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1104</th>\n",
              "      <td>150.0</td>\n",
              "      <td>Proper mental health is vital for your proper ...</td>\n",
              "      <td>898</td>\n",
              "      <td>949.0</td>\n",
              "      <td>438.0</td>\n",
              "      <td>09/15/2021 4:15</td>\n",
              "      <td>5</td>\n",
              "      <td>awareness</td>\n",
              "      <td>fort-portal</td>\n",
              "      <td>proper mental health vital proper function dai...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3599</th>\n",
              "      <td>NaN</td>\n",
              "      <td>@ sg4devpt a. 3 anxieties for me manifests thr...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>anxiety</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3835</th>\n",
              "      <td>NaN</td>\n",
              "      <td>i'm depressed about means i'm half funny till ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>depression</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>194</th>\n",
              "      <td>278.0</td>\n",
              "      <td>Women should be the last stuff to give you Stress</td>\n",
              "      <td>121</td>\n",
              "      <td>129.0</td>\n",
              "      <td>2030.0</td>\n",
              "      <td>2021-09-12 06:11:49</td>\n",
              "      <td>3</td>\n",
              "      <td>stress</td>\n",
              "      <td>nakuru</td>\n",
              "      <td>woman last stuff give stress</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2773</th>\n",
              "      <td>62.0</td>\n",
              "      <td>@Wordslinger__ Thank you, thank you ‚ù§Ô∏è‚ù§Ô∏è‚ù§Ô∏è\\n\\n...</td>\n",
              "      <td>845</td>\n",
              "      <td>3225.0</td>\n",
              "      <td>39889.0</td>\n",
              "      <td>09/13/2021 11:16</td>\n",
              "      <td>0</td>\n",
              "      <td>general tweet</td>\n",
              "      <td>kenya</td>\n",
              "      <td>wordslinger thank thank mind need calm though ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Unnamed: 0  ...                                         clean_text\n",
              "1104       150.0  ...  proper mental health vital proper function dai...\n",
              "3599         NaN  ...                                                NaN\n",
              "3835         NaN  ...                                                NaN\n",
              "194        278.0  ...                       woman last stuff give stress\n",
              "2773        62.0  ...  wordslinger thank thank mind need calm though ...\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8nRU9_1IkM0",
        "outputId": "58b91833-5b9d-43d6-b6bc-c53f08a2c429"
      },
      "source": [
        "print(train.shape)\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3885, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "id": "Q6WaXfBbTwB-",
        "outputId": "3c548db5-3220-4ff4-e74f-c5ad4041b5f1"
      },
      "source": [
        "#For substance abuse\n",
        "# Creating augmented text data to increase our training dataset by 397 entries\n",
        "\n",
        "def augment_text(df1,samples=393,pr=0.2):   #70 aurgumented data\n",
        "    aug.aug_p=pr\n",
        "    new_text=[]\n",
        "    \n",
        "    #selecting the  class samples\n",
        "    df_n=df1[df1['label']=='substance abuse'].reset_index(drop=True)\n",
        "\n",
        "    ## data augmentation loop\n",
        "    for i in tqdm(np.random.randint(0,len(df_n),samples)):\n",
        "        \n",
        "            text = df_n.iloc[i]['tweet']\n",
        "            augmented_text = aug.augment(text)\n",
        "            new_text.append(augmented_text)\n",
        "    \n",
        "    \n",
        "    ## dataframe\n",
        "    new=pd.DataFrame({'tweet':new_text,'label':'substance abuse'})\n",
        "    df1=shuffle(df1.append(new).reset_index(drop=True))\n",
        "    return df1\n",
        "   \n",
        "train = augment_text(train)\n",
        "print(train.shape, '\\n\\n')\n",
        "train.head()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 393/393 [05:28<00:00,  1.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4278, 10) \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>tweet</th>\n",
              "      <th>friends_count</th>\n",
              "      <th>followers_count</th>\n",
              "      <th>statuses_count</th>\n",
              "      <th>created_at</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>label</th>\n",
              "      <th>town</th>\n",
              "      <th>clean_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2357</th>\n",
              "      <td>257.0</td>\n",
              "      <td>@syoxxx @OleItumbi @WilliamsRuto I understand ...</td>\n",
              "      <td>188</td>\n",
              "      <td>79.0</td>\n",
              "      <td>439.0</td>\n",
              "      <td>2021-09-12 15:27:03</td>\n",
              "      <td>0</td>\n",
              "      <td>general tweet</td>\n",
              "      <td>nairobi ke</td>\n",
              "      <td>syoxxx oleitumbi williamsruto understand bro g...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>182</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>awareness</td>\n",
              "      <td>NaN</td>\n",
              "      <td>want justice came today stop dwell past think ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>583</th>\n",
              "      <td>515.0</td>\n",
              "      <td>I don't need DRUGS  because I got the most HIGHü§≤</td>\n",
              "      <td>5443</td>\n",
              "      <td>6521.0</td>\n",
              "      <td>1842.0</td>\n",
              "      <td>09-10-21 20:33</td>\n",
              "      <td>2</td>\n",
              "      <td>general tweet</td>\n",
              "      <td>kenya</td>\n",
              "      <td>need drug get high</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4203</th>\n",
              "      <td>NaN</td>\n",
              "      <td>2. agenda two from young people. drug &amp; amp ; ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>substance abuse</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2033</th>\n",
              "      <td>144.0</td>\n",
              "      <td>@bevalynekwambo3 And you big number depressed</td>\n",
              "      <td>2300</td>\n",
              "      <td>3662.0</td>\n",
              "      <td>21037.0</td>\n",
              "      <td>08-09-21 9:30</td>\n",
              "      <td>0</td>\n",
              "      <td>depression</td>\n",
              "      <td>nairobi</td>\n",
              "      <td>bevalynekwambo big number depress</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Unnamed: 0  ...                                         clean_text\n",
              "2357       257.0  ...  syoxxx oleitumbi williamsruto understand bro g...\n",
              "182          NaN  ...  want justice came today stop dwell past think ...\n",
              "583        515.0  ...                                 need drug get high\n",
              "4203         NaN  ...                                                NaN\n",
              "2033       144.0  ...                  bevalynekwambo big number depress\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKvxSLIXxfmz",
        "outputId": "63272d22-69f5-44b3-b55b-301b42ee53bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        }
      },
      "source": [
        "#For thoughts\n",
        "\n",
        "\n",
        "# Creating augmented text data to increase our training dataset by 397 entries\n",
        "\n",
        "def augment_text(df1,samples=397,pr=0.2):   #70 aurgumented data\n",
        "    aug.aug_p=pr\n",
        "    new_text=[]\n",
        "    \n",
        "    #selecting the  class samples\n",
        "    df_n=df1[df1['label']=='thoughts'].reset_index(drop=True)\n",
        "\n",
        "    ## data augmentation loop\n",
        "    for i in tqdm(np.random.randint(0,len(df_n),samples)):\n",
        "        \n",
        "            text = df_n.iloc[i]['tweet']\n",
        "            augmented_text = aug.augment(text)\n",
        "            new_text.append(augmented_text)\n",
        "    \n",
        "    \n",
        "    ## dataframe\n",
        "    new=pd.DataFrame({'tweet':new_text,'label':'thoughts'})\n",
        "    df1=shuffle(df1.append(new).reset_index(drop=True))\n",
        "    return df1\n",
        "   \n",
        "train = augment_text(train)\n",
        "print(train.shape, '\\n\\n')\n",
        "train.head()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 397/397 [05:32<00:00,  1.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4675, 10) \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>tweet</th>\n",
              "      <th>friends_count</th>\n",
              "      <th>followers_count</th>\n",
              "      <th>statuses_count</th>\n",
              "      <th>created_at</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>label</th>\n",
              "      <th>town</th>\n",
              "      <th>clean_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4269</th>\n",
              "      <td>52.0</td>\n",
              "      <td>@PlutusTheFarmer For me it‚Äôs the anxiety and h...</td>\n",
              "      <td>360</td>\n",
              "      <td>1264.0</td>\n",
              "      <td>16875.0</td>\n",
              "      <td>09/13/2021 15:20</td>\n",
              "      <td>0</td>\n",
              "      <td>general tweet</td>\n",
              "      <td>kenya</td>\n",
              "      <td>plutusthefarmer anxiety deal rude ppl always g...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90</th>\n",
              "      <td>NaN</td>\n",
              "      <td>now that it'bal s not scientifically first pro...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>depression</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>730</th>\n",
              "      <td>584.0</td>\n",
              "      <td>@muthumbinm This client needs to be put on sui...</td>\n",
              "      <td>523</td>\n",
              "      <td>694.0</td>\n",
              "      <td>14536.0</td>\n",
              "      <td>9/9/2021 11:39</td>\n",
              "      <td>0</td>\n",
              "      <td>general tweet</td>\n",
              "      <td>nairobi</td>\n",
              "      <td>muthumbinm client need put suicide watch texts...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1258</th>\n",
              "      <td>NaN</td>\n",
              "      <td>the most frequent of routine diagnosis of term...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>substance abuse</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1535</th>\n",
              "      <td>NaN</td>\n",
              "      <td>: did you know most of the athletes right espe...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>depression</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Unnamed: 0  ...                                         clean_text\n",
              "4269        52.0  ...  plutusthefarmer anxiety deal rude ppl always g...\n",
              "90           NaN  ...                                                NaN\n",
              "730        584.0  ...  muthumbinm client need put suicide watch texts...\n",
              "1258         NaN  ...                                                NaN\n",
              "1535         NaN  ...                                                NaN\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBQ0idxhxr39",
        "outputId": "24c41e35-0922-457e-df29-9bf8462645f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        }
      },
      "source": [
        "#For stress\n",
        "\n",
        "# Creating augmented text data to increase our training dataset by 413 entries\n",
        "\n",
        "def augment_text(df1,samples=413,pr=0.2):   #70 aurgumented data\n",
        "    aug.aug_p=pr\n",
        "    new_text=[]\n",
        "    \n",
        "    #selecting the  class samples\n",
        "    df_n=df1[df1['label']=='stress'].reset_index(drop=True)\n",
        "\n",
        "    ## data augmentation loop\n",
        "    for i in tqdm(np.random.randint(0,len(df_n),samples)):\n",
        "        \n",
        "            text = df_n.iloc[i]['tweet']\n",
        "            augmented_text = aug.augment(text)\n",
        "            new_text.append(augmented_text)\n",
        "    \n",
        "    \n",
        "    ## dataframe\n",
        "    new=pd.DataFrame({'tweet':new_text,'label':'stress'})\n",
        "    df1=shuffle(df1.append(new).reset_index(drop=True))\n",
        "    return df1\n",
        "   \n",
        "train = augment_text(train)\n",
        "print(train.shape, '\\n\\n')\n",
        "train.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 413/413 [05:32<00:00,  1.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5088, 10) \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>tweet</th>\n",
              "      <th>friends_count</th>\n",
              "      <th>followers_count</th>\n",
              "      <th>statuses_count</th>\n",
              "      <th>created_at</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>label</th>\n",
              "      <th>town</th>\n",
              "      <th>clean_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1348</th>\n",
              "      <td>NaN</td>\n",
              "      <td>@ high mikealfred anxiety ; levels spiking</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>anxiety</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024</th>\n",
              "      <td>100.0</td>\n",
              "      <td>Found this is my music library. How fucking cl...</td>\n",
              "      <td>401</td>\n",
              "      <td>837.0</td>\n",
              "      <td>3639.0</td>\n",
              "      <td>09/14/2021 18:23</td>\n",
              "      <td>0</td>\n",
              "      <td>general tweet</td>\n",
              "      <td>nairobi</td>\n",
              "      <td>find music library fucking classic still love ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1657</th>\n",
              "      <td>165.0</td>\n",
              "      <td>looks like the effects of burnout...played too...</td>\n",
              "      <td>2052</td>\n",
              "      <td>1024.0</td>\n",
              "      <td>38944.0</td>\n",
              "      <td>2021-09-14 10:51:59</td>\n",
              "      <td>0</td>\n",
              "      <td>stress</td>\n",
              "      <td>nairobi</td>\n",
              "      <td>look like effect burnout play much club countr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4671</th>\n",
              "      <td>360.0</td>\n",
              "      <td>#KomarockModern Health Care Facility stands wi...</td>\n",
              "      <td>9543</td>\n",
              "      <td>77549.0</td>\n",
              "      <td>129884.0</td>\n",
              "      <td>2021-09-10 09:30:06</td>\n",
              "      <td>13</td>\n",
              "      <td>general tweet</td>\n",
              "      <td>kisumu</td>\n",
              "      <td>komarockmodern health care facility stand toa ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1002</th>\n",
              "      <td>479.0</td>\n",
              "      <td>The persistent reported traumatic events such ...</td>\n",
              "      <td>257</td>\n",
              "      <td>264.0</td>\n",
              "      <td>2764.0</td>\n",
              "      <td>09/10/2021 6:39</td>\n",
              "      <td>0</td>\n",
              "      <td>depression</td>\n",
              "      <td>kenya</td>\n",
              "      <td>persistent report traumatic event violence dis...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Unnamed: 0  ...                                         clean_text\n",
              "1348         NaN  ...                                                NaN\n",
              "2024       100.0  ...  find music library fucking classic still love ...\n",
              "1657       165.0  ...  look like effect burnout play much club countr...\n",
              "4671       360.0  ...  komarockmodern health care facility stand toa ...\n",
              "1002       479.0  ...  persistent report traumatic event violence dis...\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBCXiTdZ8LFv"
      },
      "source": [
        "df_gen_tweet=df[df['label']=='general tweet']\n",
        "df_gen_tweet_under = df_gen_tweet.sample(500)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZD5CAEHl8bF_"
      },
      "source": [
        "train = train[train['label'] != 'general tweet']"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75SHK4g5jIzg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aeee4528-3ebc-4add-8518-351a16af883a"
      },
      "source": [
        "# Previewing the train dataset\n",
        "train.columns"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Unnamed: 0', 'tweet', 'friends_count', 'followers_count',\n",
              "       'statuses_count', 'created_at', 'retweet_count', 'label', 'town',\n",
              "       'clean_text'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5nrq3I4LbJYD",
        "outputId": "a0198330-f328-4424-a2ff-58e5dcfc1250"
      },
      "source": [
        "# Check the number of entries for each disorder in the train dataset\n",
        "train['label'].value_counts()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "stress             500\n",
              "awareness          500\n",
              "thoughts           500\n",
              "depression         500\n",
              "substance abuse    500\n",
              "anxiety            500\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCPbdawa8_G-"
      },
      "source": [
        "train = pd.concat([df_gen_tweet_under,train], axis=0,ignore_index=True)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBrZe8wNLwHD",
        "outputId": "ba5f38b3-61ef-486e-f9c9-be10a2854d33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Check the number of entries for each disorder in the train dataset\n",
        "train['label'].value_counts()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "stress             500\n",
              "awareness          500\n",
              "thoughts           500\n",
              "depression         500\n",
              "substance abuse    500\n",
              "general tweet      500\n",
              "anxiety            500\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5u3_1mrtVR1r",
        "outputId": "fe6b87bb-61e6-4267-8dd4-31df942131fb"
      },
      "source": [
        "# Previewing the train dataset\n",
        "train.columns"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Unnamed: 0', 'tweet', 'friends_count', 'followers_count',\n",
              "       'statuses_count', 'created_at', 'retweet_count', 'label', 'town',\n",
              "       'clean_text'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBzvOBNGSNxS"
      },
      "source": [
        "train_1=train[['tweet','label']]"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Ib-BsD5SXg9"
      },
      "source": [
        "Tweet Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bjxr3uAaTKF-",
        "outputId": "d6f23916-966c-4529-ca1d-a03bcea42734",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "#for text pre-processing\n",
        "import re, string\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import SnowballStemmer\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "#for model-building\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
        "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
        "# bag of words\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "#for word embedding\n",
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "from nltk.util import ngrams\n",
        "from spacy.lang.en import English\n",
        "nlp = English()\n",
        "import spacy\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "  \n",
        "lemmatizer = WordNetLemmatizer()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CK3EB857Xn6p",
        "outputId": "ecd05370-ab1d-4f77-f878-fcb2c1a22505",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_1['tweet']=train_1['tweet'].astype(str)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpKKr0ggQ40g",
        "outputId": "70220f65-f5d5-4f66-e167-81b7ead68beb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Remove url\n",
        "#removing the URL links\n",
        "example=\"New competition launched :https://www.kaggle.com/c/nlp-getting-started\"\n",
        "def remove_URL(text):\n",
        "    url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
        "    return url.sub(r'',text)\n",
        "\n",
        "remove_URL(example)\n",
        "train_1['tweet']=train_1['tweet'].apply(lambda x : remove_URL(x))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmRdIV2rXZT8",
        "outputId": "731beabf-cec6-4378-e31a-cb913f1c7892",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_1.dtypes"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tweet    object\n",
              "label    object\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JV-__a7jW2rf"
      },
      "source": [
        "#convert to lowercase, strip and remove punctuations\n",
        "def preprocess(text):\n",
        "    text = text.lower() \n",
        "    text=text.strip()  \n",
        "    text=re.compile('<.*?>').sub('', text) \n",
        "    text = re.compile('[%s]' % re.escape(string.punctuation)).sub(' ', text)  \n",
        "    text = re.sub('\\s+', ' ', text)  \n",
        "    text = re.sub(r'\\[[0-9]*\\]',' ',text) \n",
        "    text=re.sub(r'[^\\w\\s]', '', str(text).lower().strip())\n",
        "    text = re.sub(r'\\d',' ',text) \n",
        "    text = re.sub(r'\\s+',' ',text) \n",
        "    text = re.sub(\"@\\S+\", \"\", text)\n",
        "    re.sub(\"\\$\", \"\", text)\n",
        "    text = re.sub(\"https?:\\/\\/.*[\\r\\n]*\", \"\", text)\n",
        "    re.sub(\"#\", \"\", text)\n",
        "    return text\n",
        "\n",
        "\n",
        "#tokenizer, pos tagging and entity recognition\n",
        "\n",
        " \n",
        "# STOPWORD REMOVAL\n",
        "def stopword(string):\n",
        "    a= [i for i in string.split() if i not in stopwords.words('english')]\n",
        "    return ' '.join(a)\n",
        "#LEMMATIZATION\n",
        "# Initialize the lemmatizer\n",
        "wl = WordNetLemmatizer()\n",
        " \n",
        "# This is a helper function to map NTLK position tags\n",
        "def get_wordnet_pos(tag):\n",
        "    if tag.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    elif tag.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    elif tag.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "    elif tag.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "    else:\n",
        "        return wordnet.NOUN\n",
        "# Tokenize the sentence\n",
        "def lemmatizer(string):\n",
        "    word_pos_tags = nltk.pos_tag(word_tokenize(string)) # Get position tags\n",
        "    a=[wl.lemmatize(tag[0], get_wordnet_pos(tag[1])) for idx, tag in enumerate(word_pos_tags)] # Map the position tag and lemmatize the word/token\n",
        "    return \" \".join(a)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUU3Y0ehW9lY",
        "outputId": "ba7917fa-974c-4d0e-e0fc-dc32badaa38f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "def finalpreprocess(string):\n",
        "    return lemmatizer(stopword(preprocess(string)))\n",
        "train_1['clean_text'] = train_1['tweet'].apply(lambda x: finalpreprocess(x))\n",
        "# df = df.drop(['tweet'], axis= 1)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkYC7P-yX9_q",
        "outputId": "9b532869-1944-4f78-a01e-f781227c99b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        }
      },
      "source": [
        "train_1\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "      <th>clean_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Lord, this is the only anxiety and stress I ne...</td>\n",
              "      <td>general tweet</td>\n",
              "      <td>lord anxiety stress need</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@uhruganda  we envision to empowering and tran...</td>\n",
              "      <td>general tweet</td>\n",
              "      <td>uhruganda envision empower transform life peop...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@jwkhasndi Uzee. Age is a big factor in these ...</td>\n",
              "      <td>general tweet</td>\n",
              "      <td>jwkhasndi uzee age big factor thing huwezani n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@maijathemzungu I flew a lot as a kid ...I dun...</td>\n",
              "      <td>general tweet</td>\n",
              "      <td>maijathemzungu fly lot kid dunno happen turn s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8pm   #MazungumzoWaziWazi stress ya leo\\n@Radi...</td>\n",
              "      <td>general tweet</td>\n",
              "      <td>pm mazungumzowaziwazi stress ya leo radiojambo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3495</th>\n",
              "      <td>@iamjojo All of it, sis. The directionlessness...</td>\n",
              "      <td>depression</td>\n",
              "      <td>iamjojo si directionlessness depression pile b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3496</th>\n",
              "      <td>idk why don people disturb @ your joyjmurraya ...</td>\n",
              "      <td>depression</td>\n",
              "      <td>idk people disturb joyjmurraya see clapbacks m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3497</th>\n",
              "      <td>OVERCOME ANXIETY \\n\\nTake a time-out\\n\\nEat we...</td>\n",
              "      <td>anxiety</td>\n",
              "      <td>overcome anxiety take time eat well balanced m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3498</th>\n",
              "      <td>@tashmitambo @MisterAlbie Stress/depression. I...</td>\n",
              "      <td>stress</td>\n",
              "      <td>tashmitambo misteralbie stress depression grey...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3499</th>\n",
              "      <td>@PK2Fresh Suicide isn‚Äôt illegal in so many cou...</td>\n",
              "      <td>thoughts</td>\n",
              "      <td>pk fresh suicide isnt illegal many country acr...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3500 rows √ó 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  tweet  ...                                         clean_text\n",
              "0     Lord, this is the only anxiety and stress I ne...  ...                           lord anxiety stress need\n",
              "1     @uhruganda  we envision to empowering and tran...  ...  uhruganda envision empower transform life peop...\n",
              "2     @jwkhasndi Uzee. Age is a big factor in these ...  ...  jwkhasndi uzee age big factor thing huwezani n...\n",
              "3     @maijathemzungu I flew a lot as a kid ...I dun...  ...  maijathemzungu fly lot kid dunno happen turn s...\n",
              "4     8pm   #MazungumzoWaziWazi stress ya leo\\n@Radi...  ...  pm mazungumzowaziwazi stress ya leo radiojambo...\n",
              "...                                                 ...  ...                                                ...\n",
              "3495  @iamjojo All of it, sis. The directionlessness...  ...  iamjojo si directionlessness depression pile b...\n",
              "3496  idk why don people disturb @ your joyjmurraya ...  ...  idk people disturb joyjmurraya see clapbacks m...\n",
              "3497  OVERCOME ANXIETY \\n\\nTake a time-out\\n\\nEat we...  ...  overcome anxiety take time eat well balanced m...\n",
              "3498  @tashmitambo @MisterAlbie Stress/depression. I...  ...  tashmitambo misteralbie stress depression grey...\n",
              "3499  @PK2Fresh Suicide isn‚Äôt illegal in so many cou...  ...  pk fresh suicide isnt illegal many country acr...\n",
              "\n",
              "[3500 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mL33KloxYHpS"
      },
      "source": [
        "train_1.to_csv('Train_augmented_SD.csv')"
      ],
      "execution_count": 43,
      "outputs": []
    }
  ]
}